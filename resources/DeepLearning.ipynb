{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "11b4940c-edea-4a20-998c-1cb991364255",
    "_execution_state": "idle",
    "_uuid": "6825ae38559605f4433cb03cb41f2f0e32844de4"
   },
   "source": [
    "Breast Cancer Wisconsin (Diagnostic) Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b8458c8e-b233-49d5-9770-694bece81293",
    "_execution_state": "idle",
    "_uuid": "47783dbf4676f1bed198dbe3768f6ba487fbe975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from subprocess import check_output\n",
    "\n",
    "#\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "2f88dc98-b91a-4574-b182-069395a1a5f0",
    "_execution_state": "idle",
    "_uuid": "4e309f19617f2bcef1595de0d6df5d3bc7460844"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "      ...       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0     ...               17.33           184.60      2019.0            0.1622   \n",
       "1     ...               23.41           158.80      1956.0            0.1238   \n",
       "2     ...               25.53           152.50      1709.0            0.1444   \n",
       "3     ...               26.50            98.87       567.7            0.2098   \n",
       "4     ...               16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data file\n",
    "data = pd.read_csv('../input/data.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "c8296ef1-f658-4efa-a71a-77864d582979",
    "_execution_state": "idle",
    "_uuid": "8ea2e37ae63d8ecb4f114d437c57116a06371869",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cleaning and modifying the data\n",
    "data = data.drop('id',axis=1)\n",
    "data = data.drop('Unnamed: 32',axis=1)\n",
    "# Mapping Benign to 0 and Malignant to 1 \n",
    "data['diagnosis'] = data['diagnosis'].map({'M':1,'B':0})\n",
    "# Scaling the dataset\n",
    "datas = pd.DataFrame(preprocessing.scale(data.iloc[:,1:32]))\n",
    "datas.columns = list(data.iloc[:,1:32].columns)\n",
    "datas['diagnosis'] = data['diagnosis']\n",
    "# Creating the high dimensional feature space X\n",
    "data_drop = datas.drop('diagnosis',axis=1)\n",
    "X = data_drop.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "e1f90b94-4fe9-4edb-b49f-a4178f9438fd",
    "_execution_state": "idle",
    "_uuid": "270739d4c7599912717e58f45e14a0ba96c38963"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 381 samples, validate on 188 samples\n",
      "Epoch 1/10\n",
      "381/381 [==============================] - 0s - loss: 0.2694 - acc: 0.8845 - val_loss: 0.1108 - val_acc: 0.9521\n",
      "Epoch 2/10\n",
      "381/381 [==============================] - 0s - loss: 0.1088 - acc: 0.9738 - val_loss: 0.0728 - val_acc: 0.9787\n",
      "Epoch 3/10\n",
      "381/381 [==============================] - 0s - loss: 0.0845 - acc: 0.9659 - val_loss: 0.1053 - val_acc: 0.9681\n",
      "Epoch 4/10\n",
      "381/381 [==============================] - 0s - loss: 0.0670 - acc: 0.9764 - val_loss: 0.0517 - val_acc: 0.9787\n",
      "Epoch 5/10\n",
      "381/381 [==============================] - 0s - loss: 0.0544 - acc: 0.9843 - val_loss: 0.0684 - val_acc: 0.9787\n",
      "Epoch 6/10\n",
      "381/381 [==============================] - 0s - loss: 0.0967 - acc: 0.9711 - val_loss: 0.1367 - val_acc: 0.9415\n",
      "Epoch 7/10\n",
      "381/381 [==============================] - 0s - loss: 0.0643 - acc: 0.9764 - val_loss: 0.0410 - val_acc: 0.9840\n",
      "Epoch 8/10\n",
      "381/381 [==============================] - 0s - loss: 0.0530 - acc: 0.9790 - val_loss: 0.0652 - val_acc: 0.9840\n",
      "Epoch 9/10\n",
      "381/381 [==============================] - 0s - loss: 0.0447 - acc: 0.9869 - val_loss: 0.0705 - val_acc: 0.9787\n",
      "Epoch 10/10\n",
      "381/381 [==============================] - 0s - loss: 0.0321 - acc: 0.9895 - val_loss: 0.0869 - val_acc: 0.9734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4fa69f4e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a feed forward neural network with 3 hidden layers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input \n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128,activation=\"relu\",input_dim = np.shape(X)[1]))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# Fit and test the model by randomly splitting it \n",
    "# 67% of the data for training and 33% of the data for validation\n",
    "model.fit(X, datas['diagnosis'], batch_size=5, epochs=10,validation_split=0.33)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "db01fa8c-ec50-4941-bf31-3bc7f8c8b522",
    "_uuid": "c2a318b4a3075b3dcdd5f97ff2a759e0fe7238d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-fold cross validation accuracy -  98.59% (+/- 0.35%)\n"
     ]
    }
   ],
   "source": [
    "# Cross validation analysis \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# fix random seed for reproducibility\n",
    "seed = 3\n",
    "np.random.seed(seed)\n",
    "# K fold cross validation (k=2)\n",
    "k = 2\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "Y = datas['diagnosis']\n",
    "for train, test in kfold.split(X, Y):\n",
    "    # Fit the model\n",
    "    model.fit(X[train], Y[train], epochs=10, batch_size=10, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "    # Print scores from each cross validation run \n",
    "    # print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%d-fold cross validation accuracy -  %.2f%% (+/- %.2f%%)\" % (k,np.mean(cvscores), np.std(cvscores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
